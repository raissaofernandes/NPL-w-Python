{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "SVM.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsshnf/NPL-w-Python/blob/master/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrCXES0SJ4-V",
        "colab_type": "text"
      },
      "source": [
        "# Análise de dados utilizando SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8BeLwJcJ4-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import unicodedata\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KhyMTbzJ4-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dados_textos = pd.read_csv(\"C:\\\\Users\\\\Raissa\\\\analise\\\\brutos\\\\classificados_textos.csv\", sep=\";\", encoding='ISO-8859-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnHjQ5ilJ4-7",
        "colab_type": "code",
        "colab": {},
        "outputId": "3fdaf068-28d9-4940-d6f2-1a1328c7ac9b"
      },
      "source": [
        "dados_textos.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Voto</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Ainda tô sem palavras pra essa união e pro dia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>#AFederalLuta\\n#TiraAMãoDoNossoIF https://t.co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>É incrível ver a quantidade de estudante que a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#AFederalLuta\\n#HojeAAulaÉNaRua https://t.co/q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Um amor por essa Foto #AFEDERALLUTA \\n#TIRAAMA...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Voto                                               Text\n",
              "0     1  Ainda tô sem palavras pra essa união e pro dia...\n",
              "1     0  #AFederalLuta\\n#TiraAMãoDoNossoIF https://t.co...\n",
              "2     1  É incrível ver a quantidade de estudante que a...\n",
              "3     0  #AFederalLuta\\n#HojeAAulaÉNaRua https://t.co/q...\n",
              "4     1  Um amor por essa Foto #AFEDERALLUTA \\n#TIRAAMA..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wt3lsk7J4_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def limpeza_dados(tuites, text_field):\n",
        "    tuites[text_field] = tuites[text_field].str.lower()\n",
        "    tuites[text_field] = tuites[text_field].str.replace(r\"#\", \" \") #remove hashtags\n",
        "    tuites[text_field] = tuites[text_field].str.replace(r\"http\", \" \")\n",
        "    tuites[text_field] = tuites[text_field].str.replace(r\"http\\S+\", \" \")\n",
        "    tuites[text_field] = tuites[text_field].str.replace(r\"@\", \"at\")\n",
        "    tuites[text_field] = tuites[text_field].str.replace(r\"\\n\", \" \") #remove as linhas em branco\n",
        "    return tuites"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yaH3-A1J4_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dados_textos[\"Text\"].values.astype('U')\n",
        "y = dados_textos[\"Voto\"].values.astype('U')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iACq-fPvJ4_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#limpeza dos dados\n",
        "dados_textos_limpos = limpeza_dados(dados_textos, \"Text\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9znfnrSAJ4_n",
        "colab_type": "code",
        "colab": {},
        "outputId": "08256c1f-1ee1-46e9-bb69-a6dbfae1daf9"
      },
      "source": [
        "stopwords = ['pra', 'pro','to', 'ta','de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'a', 'com', 'nao', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'foi', 'ao', 'ele', 'das', 'tem', 'a', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'ha', 'nos', 'ja', 'esta', 'eu', 'tambam', 'sa3', 'pelo', 'pela', 'ata', 'isso', 'ela', 'entre', 'era', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'estao', 'vocaa', 'tinha', 'foram', 'essa', 'num', 'nem', 'suas', 'meu', 'a s', 'minha', 'taam', 'numa', 'pelos', 'elas', 'havia', 'seja', 'qual', 'sera', 'na3s', 'tenho', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'fosse', 'dele', 'tu', 'te', 'vocaas', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', \n",
        "'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'esta', 'estamos', 'estao', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estavamos', 'estavam', 'estivera', 'estivaramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivassemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'ha', 'havemos', 'hao', 'houve', 'houvemos', 'houveram', 'houvera', 'houvaramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvassemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houvera', 'houveremos', 'houverao', 'houveria', 'houveraamos', 'houveriam', 'sou', 'somos', 'sao', 'era', 'aramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fa ramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fa ssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'sera', 'seremos', 'serao', 'seria', 'seraamos', 'seriam', 'tenho', 'tem', 'temos', 'tam', 'tinha', 'tanhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivaramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivassemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'tera', 'teremos', 'terao', 'teria', 'teraamos', 'teriam']\n",
        "print(len(stopwords))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS2ETIbEJ4_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stopWords(sentence):\n",
        "    frase = []\n",
        "    for word in sentence.split():\n",
        "        if word not in stopwords:\n",
        "           # semStop = [p for p in word.split() if p not in stopwords]\n",
        "            frase.append(word)\n",
        "    return ' '.join(frase)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scfLtjuDJ5AC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dados_textos['Text'] = [remove_stopWords(str(t)) for t in dados_textos['Text']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSz6Ch0DJ5AU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def removerAcentosECaracteresEspeciais(palavra):\n",
        "\n",
        "    nfkd = unicodedata.normalize('NFKD', palavra)\n",
        "    palavraSemAcento = u\"\".join([c for c in nfkd if not unicodedata.combining(c)])\n",
        "    palavraSemAcento = re.sub('[^a-zA-Z0-9 \\\\\\]', '', palavraSemAcento)\n",
        "\n",
        "    return palavraSemAcento"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrwpbMIuJ5Af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dados_textos['Text'] = [removerAcentosECaracteresEspeciais(str(t)) for t in dados_textos['Text']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r56PjrUiJ5Au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#regravação do arquivo com os dados limpos \n",
        "dados_textos_limpos.to_csv(\"dados_limpos.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiMboBdjJ5A4",
        "colab_type": "code",
        "colab": {},
        "outputId": "35a518ac-4503-483d-e16c-c3a30cc55485"
      },
      "source": [
        "dados_textos_limpos.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Voto</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>ainda to palavras uniao dia hoje lindo ifc amo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>afederalluta tiraamaodonossoif stcohpn35xub6d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>e incrivel ver quantidade estudante ainda preo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>afederalluta hojeaaulaenarua stcoqazbuks6lc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>amor foto afederalluta tiraamaodomeuif stcojbj...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Voto                                               Text\n",
              "0     1  ainda to palavras uniao dia hoje lindo ifc amo...\n",
              "1     0      afederalluta tiraamaodonossoif stcohpn35xub6d\n",
              "2     1  e incrivel ver quantidade estudante ainda preo...\n",
              "3     0        afederalluta hojeaaulaenarua stcoqazbuks6lc\n",
              "4     1  amor foto afederalluta tiraamaodomeuif stcojbj..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvSpsURuJ5BE",
        "colab_type": "code",
        "colab": {},
        "outputId": "e43b86bb-4e56-4385-c27c-a0fbd7e263a8"
      },
      "source": [
        "dados_textos_limpos.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Voto</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>0</td>\n",
              "      <td>dia13erua tsunami13a stco9oib3kso6a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>0</td>\n",
              "      <td>enos tsunami13a dia13erua asruaspovo lulalivre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>1</td>\n",
              "      <td>arrumando ir derrubar governo tsunami13a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>0</td>\n",
              "      <td>dce ufmg ate presente momento nao divulgou ond...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>1</td>\n",
              "      <td>recife ficou pequena tantos jovens rua defende...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Voto                                               Text\n",
              "4994     0                dia13erua tsunami13a stco9oib3kso6a\n",
              "4995     0  enos tsunami13a dia13erua asruaspovo lulalivre...\n",
              "4996     1           arrumando ir derrubar governo tsunami13a\n",
              "4997     0  dce ufmg ate presente momento nao divulgou ond...\n",
              "4998     1  recife ficou pequena tantos jovens rua defende..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCrmg4kLJ5BM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer(analyzer = \"word\")\n",
        "X_vetor = vectorizer.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC7dQgwFJ5BT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_vetor, y, test_size = 0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AW97LI2J5Bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C = 1.0  # SVM regularization parameter\n",
        "classificador = svm.SVC(kernel='linear', C=C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCzJdBAUJ5Bq",
        "colab_type": "code",
        "colab": {},
        "outputId": "1a099cbc-34e0-4a11-9ac9-063567195835"
      },
      "source": [
        "#treinando o modelo\n",
        "classificador.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOIIgwL4J5B0",
        "colab_type": "code",
        "colab": {},
        "outputId": "2e8bf153-ee17-4504-add0-1c028c98573d"
      },
      "source": [
        "classificador.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['-1', '0', '0', ..., '1', '0', '1'], dtype='<U21')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h516V93QJ5B-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classificador.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnEhVKWdJ5CG",
        "colab_type": "code",
        "colab": {},
        "outputId": "fbd8b816-6362-4122-b51d-057120566fa7"
      },
      "source": [
        "classificador.score(X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7193333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Iscks4J5CL",
        "colab_type": "code",
        "colab": {},
        "outputId": "007f4c1f-5f0c-42dd-bd85-0083266f0310"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.29      0.34       189\n",
            "           0       0.78      0.84      0.81       811\n",
            "           1       0.69      0.69      0.69       500\n",
            "\n",
            "    accuracy                           0.72      1500\n",
            "   macro avg       0.63      0.61      0.61      1500\n",
            "weighted avg       0.70      0.72      0.71      1500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvwQmMFoJ5CQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}